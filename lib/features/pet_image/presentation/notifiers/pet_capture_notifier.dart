import 'dart:io';
import 'dart:typed_data';
import 'dart:ui' as ui;

import 'package:camerawesome/camerawesome_plugin.dart';
import 'package:flutter/material.dart';
import 'package:flutter_image_compress/flutter_image_compress.dart';
import 'package:flutter_riverpod/flutter_riverpod.dart';
import 'package:image/image.dart' as img;
import 'package:path_provider/path_provider.dart';
import 'package:pixel_love/core/providers/core_providers.dart';
import 'package:pixel_love/features/pet_image/providers/pet_image_providers.dart';

import 'pet_capture_state.dart';

class PetCaptureNotifier extends Notifier<PetCaptureState> {
  PhotoCameraState? _photoState;
  final captionController = TextEditingController();
  bool _isCapturingInProgress = false;
  AnalysisImage? _latestFrame;

  // ğŸ”¥ Sensor orientation Ä‘á»ƒ fix rotation
  SensorPosition _sensorPosition = SensorPosition.back;
  int _sensorRotation = 0;
  double _currentZoom = 1.0; // ğŸ”¥ Zoom hiá»‡n táº¡i cá»§a camera

  static const double _previewAspectRatio =
      4 / 3.9; // ğŸ”¥ Khá»›p vá»›i CaptureLayoutMetrics (4/3.9)

  @override
  PetCaptureState build() {
    return const PetCaptureState();
  }

  // ===== Attach camera =====
  void attachState(CameraState cameraState) {
    cameraState.when(
      onPhotoMode: (photoState) {
        _photoState = photoState;
        final newFlash = photoState.sensorConfig.flashMode;
        if (state.flashMode != newFlash) {
          state = state.copyWith(flashMode: newFlash);
        }

        // ğŸ”¥ Láº¤Y ZOOM Tá»ª CAMERA (QUAN TRá»ŒNG - Preview cÃ³ zoom ná»™i bá»™)
        _updateZoomFromCamera();

        // ğŸ”¥ Rotation sáº½ Ä‘Æ°á»£c láº¥y tá»« AnalysisImage trong onLiveFrame
        // KhÃ´ng cáº§n set á»Ÿ Ä‘Ã¢y vÃ¬ sáº½ Ä‘Æ°á»£c update tá»« frame Ä‘áº§u tiÃªn
        _sensorPosition = SensorPosition.back;

        debugPrint(
          'Camera attached: rotation=$_sensorRotation position=$_sensorPosition zoom=$_currentZoom',
        );
      },
    );
  }

  // ===== Update zoom tá»« camera state =====
  void _updateZoomFromCamera() {
    final ps = _photoState;
    if (ps == null) return;

    try {
      _currentZoom = ps.sensorConfig.zoom;
    } catch (_) {
      _currentZoom = 1.0; // Fallback náº¿u khÃ´ng cÃ³ zoom
    }
  }

  // ===== Helper: Convert InputAnalysisImageRotation â†’ int =====
  int _rotationToDegrees(dynamic rotation) {
    // InputAnalysisImageRotation lÃ  enum, convert sang int
    final rotationStr = rotation.toString();
    if (rotationStr.contains('90')) return 90;
    if (rotationStr.contains('180')) return 180;
    if (rotationStr.contains('270')) return 270;
    return 0; // rotation0deg hoáº·c default
  }

  // ===== Cache live frame (KHÃ”NG setState) =====
  void onLiveFrame(AnalysisImage image) {
    // ğŸ”¥ chá»‰ cache, KHÃ”NG setState
    _latestFrame = image;

    // ğŸ”¥ Láº¤Y ROTATION Tá»ª AnalysisImage (QUAN TRá»ŒNG)
    image.when(
      nv21: (nv21) {
        _sensorRotation = _rotationToDegrees(
          nv21.rotation,
        ); // âœ… Láº¥y rotation thá»±c tá»« camera
      },
      bgra8888: (bgra) {
        _sensorRotation = _rotationToDegrees(
          bgra.rotation,
        ); // âœ… Láº¥y rotation thá»±c tá»« camera
      },
    );
  }

  // ===== Freeze from live frame (LOCKET STYLE - 0ms delay) =====
  Future<void> freezeFromLiveFrame() async {
    if (state.isFrozen || _latestFrame == null) return;

    state = state.copyWith(isCapturing: true);

    try {
      // ğŸ”¥ Cáº¬P NHáº¬T ZOOM Tá»ª CAMERA STATE (Ä‘áº£m báº£o luÃ´n Ä‘Ãºng)
      _updateZoomFromCamera();

      // ğŸ”¥ Convert AnalysisImage â†’ ui.Image
      final uiImage = await _convertAnalysisImage(_latestFrame!);

      // ğŸ”¥ Váº½ ui.Image â†’ bytes (PNG, khÃ´ng crop)
      final byteData = await uiImage.toByteData(format: ui.ImageByteFormat.png);
      final bytes = byteData!.buffer.asUint8List();

      // ğŸ”¥ Freeze ngay láº­p tá»©c - khÃ´ng I/O, khÃ´ng delay
      state = state.copyWith(
        isFrozen: true,
        bytes: bytes,
        isCapturing: false,
        capturedAt: DateTime.now(),
        // âŒ KHÃ”NG set previewFile á»Ÿ Ä‘Ã¢y - sáº½ táº¡o khi send
      );
    } catch (e) {
      state = state.copyWith(isCapturing: false);
    }
  }

  // ===== Capture (LOCKET STYLE - OPTIMIZED) =====
  Future<void> capturePhoto() async {
    // ğŸ”¥ Cháº·n náº¿u Ä‘ang chá»¥p, Ä‘ang gá»­i, Ä‘Ã£ freeze rá»“i
    if (state.isCapturing ||
        state.isSending ||
        state.isFrozen ||
        _isCapturingInProgress) {
      return;
    }

    final ps = _photoState;
    if (ps == null) return;

    // ğŸ”¥ BÆ¯á»šC 1: Set flag Ä‘á»ƒ cháº·n gá»i láº¡i
    _isCapturingInProgress = true;
    state = state.copyWith(isCapturing: true);

    try {
      // ğŸ”¥ BÆ¯á»šC 2: Chá»¥p áº£nh (async, khÃ´ng Ä‘á»£i file write xong)
      final request = await ps.takePhoto();
      final path = _extractPath(request);

      if (path == null) {
        state = state.copyWith(isCapturing: false);
        return;
      }

      final file = File(path);

      // ğŸ”¥ BÆ¯á»šC 3: Äá»c bytes NGAY Ä‘á»ƒ preview (chá»‰ cáº§n bytes, khÃ´ng process)
      final bytes = await file.readAsBytes();

      // ğŸ”¥ BÆ¯á»šC 4: Freeze ngay láº­p tá»©c (1 bÆ°á»›c duy nháº¥t)
      state = state.copyWith(
        isFrozen: true, // âœ… Freeze flag
        bytes: bytes, // âœ… Preview tá»« RAM
        previewFile: file, // âœ… LÆ°u file gá»‘c táº¡m thá»i (chÆ°a process)
        capturedAt: DateTime.now(), // âœ… Giá»¯ láº¡i cho send API
        isCapturing: false,
      );

      // âŒ KHÃ”NG process file á»Ÿ Ä‘Ã¢y - sáº½ lÃ m khi send
    } catch (e) {
      state = state.copyWith(isCapturing: false);
    } finally {
      _isCapturingInProgress = false;
    }
  }

  /// Process file CHá»ˆ KHI send (thay vÃ¬ process ngay khi capture)
  Future<File?> _processFileForUpload(File originalFile) async {
    try {
      // Äá»c bytes tá»« file gá»‘c
      final originalBytes = await originalFile.readAsBytes();
      var image = img.decodeImage(originalBytes);
      if (image == null) return null;

      // ğŸ”¥ Crop áº£nh
      var processed = _cropCenter(image, _previewAspectRatio);

      // ğŸ”¥ Resize Ä‘á»ƒ Ä‘áº£m báº£o kÃ­ch thÆ°á»›c tá»‘i thiá»ƒu (giá»¯ tá»· lá»‡)
      // Äáº£m báº£o chiá»u dÃ i nháº¥t >= 1280px
      const int minLongestSide = 1280;
      final longestSide = processed.width > processed.height
          ? processed.width
          : processed.height;

      int targetWidth = processed.width;
      int targetHeight = processed.height;

      if (longestSide < minLongestSide) {
        // TÃ­nh scale factor Ä‘á»ƒ resize
        final scale = minLongestSide / longestSide;
        targetWidth = (processed.width * scale).round();
        targetHeight = (processed.height * scale).round();
        processed = img.copyResize(
          processed,
          width: targetWidth,
          height: targetHeight,
          interpolation: img.Interpolation.linear,
        );
      }

      // ğŸ”¥ LÆ°u áº£nh Ä‘Ã£ crop vÃ  resize vÃ o temp file
      final tempDir = await getTemporaryDirectory();
      final timestamp = DateTime.now().microsecondsSinceEpoch;
      final tempProcessedFile = File(
        '${tempDir.path}/pet_processed_$timestamp.jpg',
      );
      final encoded = img.encodeJpg(processed, quality: 90);
      await tempProcessedFile.writeAsBytes(encoded);

      // ğŸ”¥ DÃ¹ng flutter_image_compress Ä‘á»ƒ xÃ³a EXIF metadata vÃ  Ä‘áº£m báº£o kÃ­ch thÆ°á»›c
      // keepExif: false â†’ XÃ³a Location/GPS metadata
      final compressedBytes = await FlutterImageCompress.compressWithFile(
        tempProcessedFile.absolute.path,
        minWidth: targetWidth,
        minHeight: targetHeight,
        quality: 90,
        keepExif: false, // ğŸ”¥ QUAN TRá»ŒNG: XÃ³a EXIF metadata (Location)
      );

      if (compressedBytes == null) {
        // Fallback: dÃ¹ng file Ä‘Ã£ process náº¿u compress fail
        return tempProcessedFile;
      }

      // ğŸ”¥ LÆ°u file cuá»‘i cÃ¹ng (Ä‘Ã£ xÃ³a EXIF)
      final finalFile = File('${tempDir.path}/pet_$timestamp.jpg');
      await finalFile.writeAsBytes(compressedBytes);

      // XÃ³a temp file
      try {
        await tempProcessedFile.delete();
      } catch (_) {
        // Ignore delete error
      }

      return finalFile;
    } catch (_) {
      // Náº¿u process fail, return null Ä‘á»ƒ dÃ¹ng file gá»‘c
      return null;
    }
  }

  // ===== Reset (âŒ) =====
  void resetPreview() {
    captionController.clear();
    _isCapturingInProgress = false;
    _latestFrame = null; // Clear cached frame
    // ğŸ”¥ Clear bytes Ä‘á»ƒ trÃ¡nh leak RAM
    state = state.copyWith(
      isFrozen: false,
      clearBytes: true,
      previewFile: null,
      capturedAt: null,
    );
  }

  // ===== Set preview from gallery =====
  Future<void> setPreviewFile(File file) async {
    try {
      // ğŸ”¥ Äá»c bytes ngay cho preview
      final bytes = await file.readAsBytes();
      state = state.copyWith(
        isFrozen: true, // âœ… Freeze ngay
        bytes: bytes,
        previewFile: file, // âœ… LÆ°u file gá»‘c (chÆ°a process)
        capturedAt: DateTime.now(),
      );

      // âŒ KHÃ”NG process file á»Ÿ Ä‘Ã¢y - sáº½ lÃ m khi send
    } catch (_) {
      // Ignore error
    }
  }

  // ===== Switch camera =====
  Future<void> switchCamera() async {
    final ps = _photoState;
    if (ps == null) return;
    await ps.switchCameraSensor();

    // ğŸ”¥ Update sensor position khi switch
    _sensorPosition = _sensorPosition == SensorPosition.back
        ? SensorPosition.front
        : SensorPosition.back;
    // Rotation sáº½ Ä‘Æ°á»£c update tá»« camera state
  }

  // ===== Send =====
  Future<void> send() async {
    if (state.isSending) return;
    if (state.bytes == null) return; // ğŸ”¥ Cáº§n cÃ³ bytes Ä‘á»ƒ send

    state = state.copyWith(isSending: true);
    try {
      File? fileToUpload;

      if (state.previewFile != null) {
        // ğŸ”¥ Case: freeze tá»« capture photo hoáº·c gallery
        final originalFile = state.previewFile!;
        final processedFile = await _processFileForUpload(originalFile);
        fileToUpload = processedFile ?? originalFile;
      } else {
        // ğŸ”¥ Case: freeze tá»« live frame - táº¡o file tá»« bytes
        final tempDir = await getTemporaryDirectory();
        final timestamp = DateTime.now().microsecondsSinceEpoch;
        final tempFile = File('${tempDir.path}/pet_live_$timestamp.png');
        await tempFile.writeAsBytes(state.bytes!);

        // Process file (crop + encode to JPG)
        final processedFile = await _processFileForUpload(tempFile);
        fileToUpload = processedFile ?? tempFile;
      }

      final cloudinaryService = ref.read(cloudinaryUploadServiceProvider);
      final sendImageUseCase = ref.read(sendImageToPetUseCaseProvider);

      final uploadResult = await cloudinaryService.uploadImage(fileToUpload);

      await uploadResult.when(
        success: (url) async {
          final text = captionController.text.trim();
          final apiResult = await sendImageUseCase.call(
            imageUrl: url,
            takenAt: state.capturedAt,
            text: text.isEmpty ? null : text,
          );

          apiResult.when(
            success: (_) {
              resetPreview();
              state = state.copyWith(isSending: false);
            },
            error: (_) {
              state = state.copyWith(isSending: false);
            },
          );
        },
        error: (_) {
          state = state.copyWith(isSending: false);
        },
      );
    } catch (_) {
      state = state.copyWith(isSending: false);
    }
  }

  // ===== Flash =====
  Future<void> toggleFlash() async {
    final ps = _photoState;
    if (ps == null) return;

    FlashMode next;
    switch (state.flashMode) {
      case FlashMode.auto:
        next = FlashMode.on;
        break;
      case FlashMode.on:
        next = FlashMode.always;
        break;
      case FlashMode.always:
        next = FlashMode.none;
        break;
      case FlashMode.none:
        next = FlashMode.auto;
        break;
    }

    await ps.sensorConfig.setFlashMode(next);
    state = state.copyWith(flashMode: next);
  }

  // ===== Helpers =====
  String? _extractPath(CaptureRequest request) {
    return request.when(
      single: (s) => s.file?.path,
      multiple: (m) => m.fileBySensor.values.first?.path,
    );
  }

  img.Image _cropCenter(img.Image src, double aspect) {
    final srcAspect = src.width / src.height;

    int w, h;
    if (srcAspect > aspect) {
      h = src.height;
      w = (h * aspect).round();
    } else {
      w = src.width;
      h = (w / aspect).round();
    }

    final x = (src.width - w) ~/ 2;
    final y = (src.height - h) ~/ 2;
    return img.copyCrop(src, x: x, y: y, width: w, height: h);
  }

  // ===== Convert AnalysisImage â†’ ui.Image =====
  Future<ui.Image> _convertAnalysisImage(AnalysisImage image) async {
    final result = await image.when(
      nv21: (nv21) async {
        final width = nv21.width;
        final height = nv21.height;

        // ğŸ”¥ Debug log
        debugPrint(
          'NV21 frame: ${width}x${height}, bytes=${nv21.bytes.length}',
        );

        // 1ï¸âƒ£ Convert NV21 â†’ RGB image (image package)
        var rgbImage = img.Image(width: width, height: height);

        // ğŸ”¥ BÆ¯á»šC Sá»NG CÃ’N: Manual NV21 â†’ RGB conversion
        _convertNV21ToRGB(nv21.bytes, width, height, rgbImage);

        // ğŸ”¥ FIX ORIENTATION - Rotate + flip Ä‘á»ƒ khá»›p preview
        rgbImage = _applyOrientation(
          rgbImage,
          _sensorRotation,
          _sensorPosition,
        );

        // ğŸ”¥ BÃ™ ZOOM CHO GIá»NG PREVIEW (SAU rotate)
        rgbImage = _applyZoom(rgbImage, _currentZoom);

        // 2ï¸âƒ£ Encode RGB â†’ PNG
        final pngBytes = img.encodePng(rgbImage);

        // 3ï¸âƒ£ Decode PNG â†’ ui.Image
        final codec = await ui.instantiateImageCodec(pngBytes);
        final frame = await codec.getNextFrame();

        return frame.image;
      },
      bgra8888: (bgra) async {
        // ğŸ”¥ Decode BGRA â†’ RGB image Ä‘á»ƒ apply orientation
        var rgbImage = img.Image(width: bgra.width, height: bgra.height);

        // Convert BGRA â†’ RGB
        for (int y = 0; y < bgra.height; y++) {
          for (int x = 0; x < bgra.width; x++) {
            final index = (y * bgra.width + x) * 4;
            if (index + 3 >= bgra.bytes.length) continue;

            final b = bgra.bytes[index];
            final g = bgra.bytes[index + 1];
            final r = bgra.bytes[index + 2];
            // index + 3 lÃ  alpha, bá» qua

            rgbImage.setPixelRgb(x, y, r, g, b);
          }
        }

        // ğŸ”¥ FIX ORIENTATION - Rotate + flip Ä‘á»ƒ khá»›p preview
        rgbImage = _applyOrientation(
          rgbImage,
          _rotationToDegrees(
            bgra.rotation,
          ), // âœ… DÃ¹ng rotation tá»« bgra (convert sang int)
          _sensorPosition,
        );

        // ğŸ”¥ BÃ™ ZOOM CHO GIá»NG PREVIEW (SAU rotate)
        rgbImage = _applyZoom(rgbImage, _currentZoom);

        // Encode RGB â†’ PNG
        final pngBytes = img.encodePng(rgbImage);

        // Decode PNG â†’ ui.Image
        final codec = await ui.instantiateImageCodec(pngBytes);
        final frame = await codec.getNextFrame();
        return frame.image;
      },
    );

    return result ?? (throw Exception('Failed to convert AnalysisImage'));
  }

  // ===== Manual NV21 â†’ RGB conversion =====
  void _convertNV21ToRGB(
    Uint8List nv21Bytes,
    int width,
    int height,
    img.Image rgbImage,
  ) {
    // NV21 format: Y plane (width * height) + interleaved VU plane (width * height / 2)
    final ySize = width * height;

    for (int y = 0; y < height; y++) {
      for (int x = 0; x < width; x++) {
        // Get Y (luminance)
        final yIndex = y * width + x;
        if (yIndex >= nv21Bytes.length) continue;
        final yValue = nv21Bytes[yIndex];

        // Get UV (chrominance) - NV21 is interleaved VU
        final uvIndex = ySize + ((y ~/ 2) * width) + (x ~/ 2) * 2;
        final vValue = uvIndex < nv21Bytes.length ? nv21Bytes[uvIndex] : 128;
        final uValue = uvIndex + 1 < nv21Bytes.length
            ? nv21Bytes[uvIndex + 1]
            : 128;

        // Convert YUV to RGB
        final r = _yuvToR(yValue, uValue, vValue);
        final g = _yuvToG(yValue, uValue, vValue);
        final b = _yuvToB(yValue, uValue, vValue);

        rgbImage.setPixelRgb(x, y, r, g, b);
      }
    }
  }

  int _yuvToR(int y, int u, int v) {
    final r = (y + 1.402 * (v - 128)).round();
    return r.clamp(0, 255);
  }

  int _yuvToG(int y, int u, int v) {
    final g = (y - 0.344 * (u - 128) - 0.714 * (v - 128)).round();
    return g.clamp(0, 255);
  }

  int _yuvToB(int y, int u, int v) {
    final b = (y + 1.772 * (u - 128)).round();
    return b.clamp(0, 255);
  }

  // ===== Apply orientation - Rotate + flip Ä‘á»ƒ khá»›p preview =====
  img.Image _applyOrientation(
    img.Image src,
    int rotation,
    SensorPosition position,
  ) {
    img.Image out = src;

    // âœ… Rotate theo rotation THá»°C tá»« camera (KHÃ”NG xoay ngÆ°á»£c)
    switch (rotation) {
      case 90:
        out = img.copyRotate(out, angle: 90);
        break;
      case 180:
        out = img.copyRotate(out, angle: 180);
        break;
      case 270:
        out = img.copyRotate(out, angle: 270);
        break;
      // case 0: khÃ´ng cáº§n rotate
    }

    // âœ… Mirror chá»‰ khi camera trÆ°á»›c
    if (position == SensorPosition.front) {
      out = img.flipHorizontal(out);
    }

    return out;
  }

  // ===== Apply zoom - Crop center Ä‘á»ƒ khá»›p preview zoom =====
  img.Image _applyZoom(img.Image src, double zoom) {
    // ğŸ”¥ (A) BÃ¹ nháº¹ khi zoom = 1.0 (CameraAwesome cÃ³ internal scale ~1.03-1.08x)
    // Preview thá»±c táº¿ cÃ³ thá»ƒ lÃ  1.05x nhÆ°ng _currentZoom = 1.0
    // Empiric value, test trÃªn Pixel (Instagram cÅ©ng lÃ m kiá»ƒu "empiric fudge factor" nÃ y)
    final effectiveZoom = zoom <= 1.01 ? 1.05 : zoom;

    // ğŸ”¥ Crop center: giáº£m kÃ­ch thÆ°á»›c theo zoom
    final newWidth = (src.width / effectiveZoom).round();
    final newHeight = (src.height / effectiveZoom).round();

    final x = (src.width - newWidth) ~/ 2;

    // ğŸ”¥ (B) Dá»‹ch crop Y lÃªn nháº¹ theo previewAlignment (0, -0.37)
    // Preview bá»‹ dá»‹ch lÃªn trÃªn â†’ cáº£m giÃ¡c zoom hÆ¡n â†’ dá»‹ch crop Y lÃªn Ä‘á»ƒ khá»›p cáº£m giÃ¡c thá»‹ giÃ¡c
    final yOffset = (src.height * 0.05)
        .round(); // ~5% height, tÆ°Æ¡ng á»©ng vá»›i -0.37 alignment
    final y = ((src.height - newHeight) ~/ 2) - yOffset;

    // ğŸ”¥ Clamp Y Ä‘á»ƒ khÃ´ng vÆ°á»£t quÃ¡ bounds
    final clampedY = y.clamp(0, src.height - newHeight);

    return img.copyCrop(
      src,
      x: x,
      y: clampedY,
      width: newWidth,
      height: newHeight,
    );
  }
}
