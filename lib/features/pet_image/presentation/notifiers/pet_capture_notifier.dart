import 'dart:async';
import 'dart:io';
import 'dart:typed_data';
import 'dart:ui' as ui;

import 'package:camerawesome/camerawesome_plugin.dart';
import 'package:flutter/material.dart';
import 'package:flutter_image_compress/flutter_image_compress.dart';
import 'package:flutter_riverpod/flutter_riverpod.dart';
import 'package:image/image.dart' as img;
import 'package:path_provider/path_provider.dart';
import 'package:pixel_love/core/providers/core_providers.dart';
import 'package:pixel_love/features/pet_image/providers/pet_image_providers.dart';

import 'pet_capture_state.dart';

class PetCaptureNotifier extends Notifier<PetCaptureState> {
  PhotoCameraState? _photoState;
  final captionController = TextEditingController();
  bool _isCapturingInProgress = false;
  AnalysisImage? _latestFrame;

  // üî• Sensor orientation ƒë·ªÉ fix rotation
  SensorPosition _sensorPosition = SensorPosition.back;
  int _sensorRotation = 0;
  double _currentZoom = 1.0; // üî• Zoom hi·ªán t·∫°i c·ªßa camera

  static const double _previewAspectRatio =
      4 / 3.9; // üî• Kh·ªõp v·ªõi CaptureLayoutMetrics (4/3.9)

  @override
  PetCaptureState build() {
    return const PetCaptureState();
  }

  // ===== Attach camera =====
  void attachState(CameraState cameraState) {
    cameraState.when(
      onPhotoMode: (photoState) {
        _photoState = photoState;
        final newFlash = photoState.sensorConfig.flashMode;
        if (state.flashMode != newFlash) {
          state = state.copyWith(
            flashMode: newFlash,
            sensorPosition: photoState.sensorConfig.sensors.first.position,
          );
        }

        // üî• L·∫§Y ZOOM T·ª™ CAMERA (QUAN TR·ªåNG - Preview c√≥ zoom n·ªôi b·ªô)
        _updateZoomFromCamera();

        // üî• Rotation s·∫Ω ƒë∆∞·ª£c l·∫•y t·ª´ AnalysisImage trong onLiveFrame
        // Kh√¥ng c·∫ßn set ·ªü ƒë√¢y v√¨ s·∫Ω ƒë∆∞·ª£c update t·ª´ frame ƒë·∫ßu ti√™n
        _sensorPosition = SensorPosition.back;

        debugPrint(
          'Camera attached: rotation=$_sensorRotation position=$_sensorPosition zoom=$_currentZoom',
        );
      },
    );
  }

  // ===== Update zoom t·ª´ camera state =====
  void _updateZoomFromCamera() {
    final ps = _photoState;
    if (ps == null) return;

    try {
      _currentZoom = ps.sensorConfig.zoom;
    } catch (_) {
      _currentZoom = 1.0; // Fallback n·∫øu kh√¥ng c√≥ zoom
    }
  }

  // ===== Helper: Convert InputAnalysisImageRotation ‚Üí int =====
  int _rotationToDegrees(dynamic rotation) {
    // InputAnalysisImageRotation l√† enum, convert sang int
    final rotationStr = rotation.toString();
    if (rotationStr.contains('90')) return 90;
    if (rotationStr.contains('180')) return 180;
    if (rotationStr.contains('270')) return 270;
    return 0; // rotation0deg ho·∫∑c default
  }

  // ===== Cache live frame (KH√îNG setState) =====
  void onLiveFrame(AnalysisImage image) {
    // üî• ch·ªâ cache, KH√îNG setState
    _latestFrame = image;

    // üî• L·∫§Y ROTATION T·ª™ AnalysisImage (QUAN TR·ªåNG)
    image.when(
      nv21: (nv21) {
        _sensorRotation = _rotationToDegrees(
          nv21.rotation,
        ); // ‚úÖ L·∫•y rotation th·ª±c t·ª´ camera
      },
      bgra8888: (bgra) {
        _sensorRotation = _rotationToDegrees(
          bgra.rotation,
        ); // ‚úÖ L·∫•y rotation th·ª±c t·ª´ camera
      },
    );
  }

  // ===== Freeze from live frame (LOCKET STYLE - 0ms delay) =====
  Future<void> freezeFromLiveFrame() async {
    if (state.isFrozen || _latestFrame == null) return;

    state = state.copyWith(isCapturing: true);

    try {
      _updateZoomFromCamera();
      final uiImage = await _convertAnalysisImage(_latestFrame!);

      // üî• Freeze L·∫¨P T·ª®C: Kh√¥ng encode PNG/JPG, d√πng lu√¥n ui.Image
      state = state.copyWith(
        isFrozen: true,
        frozenImage: uiImage,
        isCapturing: false,
        capturedAt: DateTime.now(),
        sensorRotation: _sensorRotation,
        sensorPosition: _sensorPosition,
      );

      // L∆∞u bytes ng·∫ßm (PNG ƒë·ªÉ hi·ªÉn th·ªã ƒë∆∞·ª£c trong MemoryImage) cho swipe screen
      uiImage.toByteData(format: ui.ImageByteFormat.png).then((data) {
        if (data != null) {
          state = state.copyWith(bytes: data.buffer.asUint8List());
        }
      });
    } catch (e) {
      state = state.copyWith(isCapturing: false);
    }
  }

  // ===== Capture (LOCKET STYLE - OPTIMIZED) =====
  Future<void> capturePhoto() async {
    // üî• Ch·∫∑n n·∫øu ƒëang ch·ª•p, ƒëang g·ª≠i, ƒë√£ freeze r·ªìi
    if (state.isCapturing ||
        state.isSending ||
        state.isFrozen ||
        _isCapturingInProgress) {
      return;
    }

    final ps = _photoState;
    if (ps == null) return;

    // üî• B∆Ø·ªöC 1: Set flag ƒë·ªÉ ch·∫∑n g·ªçi l·∫°i
    _isCapturingInProgress = true;
    state = state.copyWith(isCapturing: true);

    try {
      // üî• B∆Ø·ªöC 2: Ch·ª•p ·∫£nh (async, kh√¥ng ƒë·ª£i file write xong)
      final request = await ps.takePhoto();
      final path = _extractPath(request);

      if (path == null) {
        state = state.copyWith(isCapturing: false);
        return;
      }

      final file = File(path);

      // üî• B∆Ø·ªöC 3: ƒê·ªçc bytes NGAY ƒë·ªÉ preview (ch·ªâ c·∫ßn bytes, kh√¥ng process)
      final bytes = await file.readAsBytes();

      // üî• B∆Ø·ªöC 4: Freeze ngay l·∫≠p t·ª©c (1 b∆∞·ªõc duy nh·∫•t)
      state = state.copyWith(
        isFrozen: true, // ‚úÖ Freeze flag
        bytes: bytes, // ‚úÖ Preview t·ª´ RAM
        previewFile: file, // ‚úÖ L∆∞u file g·ªëc t·∫°m th·ªùi (ch∆∞a process)
        capturedAt: DateTime.now(), // ‚úÖ Gi·ªØ l·∫°i cho send API
        isCapturing: false,
      );

      // ‚ùå KH√îNG process file ·ªü ƒë√¢y - s·∫Ω l√†m khi send
    } catch (e) {
      state = state.copyWith(isCapturing: false);
    } finally {
      _isCapturingInProgress = false;
    }
  }

  /// Process file CH·ªà KHI send (thay v√¨ process ngay khi capture)
  Future<File?> _processFileForUpload(File originalFile) async {
    try {
      // ƒê·ªçc bytes t·ª´ file g·ªëc
      final originalBytes = await originalFile.readAsBytes();
      var image = img.decodeImage(originalBytes);
      if (image == null) return null;

      // üî• √Åp d·ª•ng rotation v√† mirror t·ª´ c·∫£m bi·∫øn
      if (state.sensorRotation != 0) {
        image = img.copyRotate(image, angle: state.sensorRotation);
      }
      if (state.sensorPosition == SensorPosition.front) {
        image = img.flipHorizontal(image);
      }

      // üî• Crop ·∫£nh
      var processed = _cropCenter(image, _previewAspectRatio);

      // üî• Resize ƒë·ªÉ ƒë·∫£m b·∫£o k√≠ch th∆∞·ªõc t·ªëi thi·ªÉu (gi·ªØ t·ª∑ l·ªá)
      // ƒê·∫£m b·∫£o chi·ªÅu d√†i nh·∫•t >= 1280px
      const int minLongestSide = 1280;
      final longestSide = processed.width > processed.height
          ? processed.width
          : processed.height;

      int targetWidth = processed.width;
      int targetHeight = processed.height;

      if (longestSide < minLongestSide) {
        // T√≠nh scale factor ƒë·ªÉ resize
        final scale = minLongestSide / longestSide;
        targetWidth = (processed.width * scale).round();
        targetHeight = (processed.height * scale).round();
        processed = img.copyResize(
          processed,
          width: targetWidth,
          height: targetHeight,
          interpolation: img.Interpolation.linear,
        );
      }

      // üî• L∆∞u ·∫£nh ƒë√£ crop v√† resize v√†o temp file
      final tempDir = await getTemporaryDirectory();
      final timestamp = DateTime.now().microsecondsSinceEpoch;
      final tempProcessedFile = File(
        '${tempDir.path}/pet_processed_$timestamp.jpg',
      );
      final encoded = img.encodeJpg(processed, quality: 90);
      await tempProcessedFile.writeAsBytes(encoded);

      // üî• D√πng flutter_image_compress ƒë·ªÉ x√≥a EXIF metadata v√† ƒë·∫£m b·∫£o k√≠ch th∆∞·ªõc
      // keepExif: false ‚Üí X√≥a Location/GPS metadata
      final compressedBytes = await FlutterImageCompress.compressWithFile(
        tempProcessedFile.absolute.path,
        minWidth: targetWidth,
        minHeight: targetHeight,
        quality: 90,
        keepExif: false, // üî• QUAN TR·ªåNG: X√≥a EXIF metadata (Location)
      );

      if (compressedBytes == null) {
        // Fallback: d√πng file ƒë√£ process n·∫øu compress fail
        return tempProcessedFile;
      }

      // üî• L∆∞u file cu·ªëi c√πng (ƒë√£ x√≥a EXIF)
      final finalFile = File('${tempDir.path}/pet_$timestamp.jpg');
      await finalFile.writeAsBytes(compressedBytes);

      // X√≥a temp file
      try {
        await tempProcessedFile.delete();
      } catch (_) {
        // Ignore delete error
      }

      return finalFile;
    } catch (_) {
      // N·∫øu process fail, return null ƒë·ªÉ d√πng file g·ªëc
      return null;
    }
  }

  // ===== Reset (‚ùå) =====
  void resetPreview() {
    captionController.clear();
    _isCapturingInProgress = false;
    _latestFrame = null; // Clear cached frame
    // üî• Clear bytes ƒë·ªÉ tr√°nh leak RAM
    state = state.copyWith(
      isFrozen: false,
      clearBytes: true,
      previewFile: null,
      capturedAt: null,
    );
  }

  // ===== Set preview from gallery =====
  Future<void> setPreviewFile(File file) async {
    try {
      // üî• ƒê·ªçc bytes ngay cho preview
      final bytes = await file.readAsBytes();
      state = state.copyWith(
        isFrozen: true, // ‚úÖ Freeze ngay
        bytes: bytes,
        previewFile: file, // ‚úÖ L∆∞u file g·ªëc (ch∆∞a process)
        capturedAt: DateTime.now(),
      );

      // ‚ùå KH√îNG process file ·ªü ƒë√¢y - s·∫Ω l√†m khi send
    } catch (_) {
      // Ignore error
    }
  }

  // ===== Switch camera =====
  Future<void> switchCamera() async {
    final ps = _photoState;
    if (ps == null) return;
    await ps.switchCameraSensor();

    // üî• Update sensor position khi switch
    _sensorPosition = _sensorPosition == SensorPosition.back
        ? SensorPosition.front
        : SensorPosition.back;
    // Rotation s·∫Ω ƒë∆∞·ª£c update t·ª´ camera state
  }

  // ===== Send =====
  void send() {
    if (state.isSending) return;

    // üî• 1. T·∫Øt b√†n ph√≠m ngay l·∫≠p t·ª©c ƒë·ªÉ gi·∫£i ph√≥ng UI thread
    FocusManager.instance.primaryFocus?.unfocus();

    if (state.bytes == null) return;

    // üî• 2. K√≠ch ho·∫°t chuy·ªÉn trang NGAY L·∫¨P T·ª®C qua listener
    state = state.copyWith(isSending: true);

    // üî• 3. Set temporary image ƒë·ªÉ m√†n h√¨nh album c√≥ data ngay
    ref
        .read(temporaryCapturedImageProvider.notifier)
        .setImage(
          TemporaryCapturedImage(
            bytes: state.bytes!,
            caption: captionController.text.trim().isEmpty
                ? null
                : captionController.text.trim(),
            capturedAt: state.capturedAt ?? DateTime.now(),
            sensorRotation: state.sensorRotation,
            sensorPosition: state.sensorPosition,
          ),
        );

    // üî• 4. Ch·∫°y c√°c t√°c v·ª• n·∫∑ng ng·∫ßm (Xoay ·∫£nh + Upload) - sau khi ƒë√£ ra l·ªánh chuy·ªÉn trang
    _uploadWithOrientedUpdate();
  }

  // Ch·∫°y background x·ª≠ l√Ω orient v√† upload
  Future<void> _uploadWithOrientedUpdate() async {
    // Xoay ·∫£nh local chu·∫©n h√≥a l·∫°i (ng·∫ßm)
    final oriented = await _generateOrientedBytes();
    if (oriented != null) {
      // C·∫≠p nh·∫≠t l·∫°i temporary image v·ªõi b·∫£n ƒë√£ xoay ƒë·∫πp h∆°n
      final currentTemp = ref.read(temporaryCapturedImageProvider);
      if (currentTemp != null) {
        ref
            .read(temporaryCapturedImageProvider.notifier)
            .setImage(
              TemporaryCapturedImage(
                bytes: oriented,
                caption: currentTemp.caption,
                capturedAt: currentTemp.capturedAt,
              ),
            );
      }
    }
    // Ti·∫øn h√†nh upload nh∆∞ c≈©
    await _uploadInBackground();
  }

  // ===== Upload ng·∫ßm (background) =====
  Future<void> _uploadInBackground() async {
    try {
      File? fileToUpload;

      if (state.previewFile != null) {
        // üî• Case: freeze t·ª´ capture photo ho·∫∑c gallery
        final originalFile = state.previewFile!;
        final processedFile = await _processFileForUpload(originalFile);
        fileToUpload = processedFile ?? originalFile;
      } else {
        // üî• Case: freeze t·ª´ live frame - t·∫°o file t·ª´ bytes ho·∫∑c frozenImage
        final tempDir = await getTemporaryDirectory();
        final timestamp = DateTime.now().microsecondsSinceEpoch;
        final tempFile = File('${tempDir.path}/pet_live_$timestamp.png');

        if (state.bytes != null) {
          await tempFile.writeAsBytes(state.bytes!);
        } else if (state.frozenImage != null) {
          final png = await state.frozenImage!.toByteData(
            format: ui.ImageByteFormat.png,
          );
          if (png != null)
            await tempFile.writeAsBytes(png.buffer.asUint8List());
        }

        // Process file (crop + encode to JPG)
        final processedFile = await _processFileForUpload(tempFile);
        fileToUpload = processedFile ?? tempFile;
      }

      final cloudinaryService = ref.read(cloudinaryUploadServiceProvider);
      final sendImageUseCase = ref.read(sendImageToPetUseCaseProvider);

      final uploadResult = await cloudinaryService.uploadImage(fileToUpload);

      await uploadResult.when(
        success: (url) async {
          final text = captionController.text.trim();
          final apiResult = await sendImageUseCase.call(
            imageUrl: url,
            takenAt: state.capturedAt,
            text: text.isEmpty ? null : text,
          );

          apiResult.when(
            success: (_) {
              // üî• Upload th√†nh c√¥ng - KH√îNG clear temporary image
              // Temporary image s·∫Ω LU√îN hi·ªÉn th·ªã ·ªü v·ªã tr√≠ ƒë·∫ßu ti√™n
              // Ch·ªâ refresh album ƒë·ªÉ c·∫≠p nh·∫≠t danh s√°ch (ƒë·ªÉ l·∫•y EXP t·ª´ server)
              ref.read(petAlbumNotifierProvider.notifier).refresh();
              // üî• Set isSending = false sau khi upload xong
              state = state.copyWith(isSending: false);
            },
            error: (_) {
              // üî• Upload l·ªói - v·∫´n gi·ªØ temporary image ƒë·ªÉ user th·∫•y
              // C√≥ th·ªÉ th√™m retry logic sau
              state = state.copyWith(isSending: false);
            },
          );
        },
        error: (_) {
          // üî• Upload l·ªói - v·∫´n gi·ªØ temporary image
          state = state.copyWith(isSending: false);
        },
      );
    } catch (_) {
      // üî• Upload l·ªói - v·∫´n gi·ªØ temporary image
      state = state.copyWith(isSending: false);
    }
  }

  // ===== Flash =====
  Future<void> toggleFlash() async {
    final ps = _photoState;
    if (ps == null) return;

    FlashMode next;
    switch (state.flashMode) {
      case FlashMode.auto:
        next = FlashMode.on;
        break;
      case FlashMode.on:
        next = FlashMode.always;
        break;
      case FlashMode.always:
        next = FlashMode.none;
        break;
      case FlashMode.none:
        next = FlashMode.auto;
        break;
    }

    await ps.sensorConfig.setFlashMode(next);
    state = state.copyWith(flashMode: next);
  }

  // ===== Helpers =====
  Future<Uint8List?> _generateOrientedBytes() async {
    final uiImage = state.frozenImage;
    if (uiImage == null) return state.bytes;

    final recorder = ui.PictureRecorder();
    final canvas = Canvas(recorder);

    final bool isRotated =
        state.sensorRotation == 90 || state.sensorRotation == 270;
    final outW = isRotated ? uiImage.height : uiImage.width;
    final outH = isRotated ? uiImage.width : uiImage.height;

    final center = Offset(outW / 2, outH / 2);
    canvas.translate(center.dx, center.dy);

    if (state.sensorRotation != 0) {
      canvas.rotate(state.sensorRotation * 3.1415926535897932 / 180);
    }

    if (state.sensorPosition == SensorPosition.front) {
      canvas.scale(-1, 1);
    }

    canvas.drawImage(
      uiImage,
      Offset(-uiImage.width / 2, -uiImage.height / 2),
      Paint()..filterQuality = ui.FilterQuality.high,
    );

    final picture = recorder.endRecording();
    final orientedImage = await picture.toImage(outW, outH);
    final data = await orientedImage.toByteData(format: ui.ImageByteFormat.png);
    return data?.buffer.asUint8List();
  }

  String? _extractPath(CaptureRequest request) {
    return request.when(
      single: (s) => s.file?.path,
      multiple: (m) => m.fileBySensor.values.first?.path,
    );
  }

  img.Image _cropCenter(img.Image src, double aspect) {
    final srcAspect = src.width / src.height;

    int w, h;
    if (srcAspect > aspect) {
      h = src.height;
      w = (h * aspect).round();
    } else {
      w = src.width;
      h = (w / aspect).round();
    }

    final x = (src.width - w) ~/ 2;
    final y = (src.height - h) ~/ 2;
    return img.copyCrop(src, x: x, y: y, width: w, height: h);
  }

  // ===== Convert AnalysisImage ‚Üí ui.Image =====
  Future<ui.Image> _convertAnalysisImage(AnalysisImage image) async {
    final result = await image.when(
      nv21: (nv21) async {
        final width = nv21.width;
        final height = nv21.height;

        // 1Ô∏è‚É£ Convert NV21 ‚Üí RGBA bytes ngay l·∫≠p t·ª©c (hi·∫øm khi kh·ª±ng v√¨ l√† loop ƒë∆°n gi·∫£n)
        final rgbaBytes = Uint8List(width * height * 4);
        _convertNV21ToRGBA(nv21.bytes, width, height, rgbaBytes);

        // 2Ô∏è‚É£ D√πng decodeImageFromPixels cho t·ªëc ƒë·ªô (g·∫ßn nh∆∞ 0ms)
        final completer = Completer<ui.Image>();
        ui.decodeImageFromPixels(
          rgbaBytes,
          width,
          height,
          ui.PixelFormat.rgba8888,
          (ui.Image image) => completer.complete(image),
        );
        return completer.future;
      },
      bgra8888: (bgra) async {
        // BGRA ‚Üí RGBA ch·ªâ l√† ƒë·ªïi v·ªã tr√≠ R v√† B
        final rgbaBytes = Uint8List(bgra.bytes.length);
        for (int i = 0; i < bgra.bytes.length; i += 4) {
          rgbaBytes[i] = bgra.bytes[i + 2]; // R
          rgbaBytes[i + 1] = bgra.bytes[i + 1]; // G
          rgbaBytes[i + 2] = bgra.bytes[i]; // B
          rgbaBytes[i + 3] = bgra.bytes[i + 3]; // A
        }

        final completer = Completer<ui.Image>();
        ui.decodeImageFromPixels(
          rgbaBytes,
          bgra.width,
          bgra.height,
          ui.PixelFormat.rgba8888,
          (ui.Image image) => completer.complete(image),
        );
        return completer.future;
      },
    );

    return result ?? (throw Exception('Failed to convert AnalysisImage'));
  }

  // ===== Manual NV21 ‚Üí RGBA conversion (SI√äU NHANH) =====
  void _convertNV21ToRGBA(
    Uint8List nv21Bytes,
    int width,
    int height,
    Uint8List rgbaBytes,
  ) {
    final ySize = width * height;
    int rgbaIndex = 0;

    for (int y = 0; y < height; y++) {
      for (int x = 0; x < width; x++) {
        final yIndex = y * width + x;
        final yValue = nv21Bytes[yIndex];

        final uvIndex = ySize + ((y ~/ 2) * width) + (x ~/ 2) * 2;
        final vValue = uvIndex < nv21Bytes.length ? nv21Bytes[uvIndex] : 128;
        final uValue = uvIndex + 1 < nv21Bytes.length
            ? nv21Bytes[uvIndex + 1]
            : 128;

        final r = (yValue + 1.402 * (vValue - 128)).round().clamp(0, 255);
        final g = (yValue - 0.344 * (uValue - 128) - 0.714 * (vValue - 128))
            .round()
            .clamp(0, 255);
        final b = (yValue + 1.772 * (uValue - 128)).round().clamp(0, 255);

        rgbaBytes[rgbaIndex++] = r;
        rgbaBytes[rgbaIndex++] = g;
        rgbaBytes[rgbaIndex++] = b;
        rgbaBytes[rgbaIndex++] = 255; // Alpha
      }
    }
  }

  // orientation and zoom calculations are now handled in the CustomPainter for maximum speed
}
